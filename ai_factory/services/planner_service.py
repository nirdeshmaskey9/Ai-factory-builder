import logging
import os
import json
from typing import List
from ai_factory.models import PlanStep, TaskType, DispatchResponse
from ai_factory.memory.memory_embeddings import add_to_memory

try:
    # Optional import; tests may run without OpenAI installed
    from openai import OpenAI  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    OpenAI = None  # type: ignore

logger = logging.getLogger(__name__)


class StubPlanner:
    """
    A simple, deterministic planner that turns a prompt into a few actionable steps.
    This is a placeholder for a future model-driven planner.
    """

    def _heuristic_decompose(self, prompt: str, task_type: TaskType) -> List[PlanStep]:
        # Basic heuristics to split into steps by punctuation or conjunctions
        text = " ".join(prompt.strip().split())
        candidates = []
        # Split on obvious boundaries
        for sep in [".", ";", " and then ", " then ", " -> ", " — "]:
            parts = []
            if sep in text:
                parts = [p.strip(" -—>.;") for p in text.split(sep)]
                candidates = [p for p in parts if p]
                break
        if not candidates:
            # Fallback: naive chunking by ~12 words
            words = text.split()
            chunk = 12
            candidates = [" ".join(words[i:i+chunk]) for i in range(0, len(words), chunk)]

        steps: List[PlanStep] = []
        for idx, c in enumerate(candidates):
            steps.append(
                PlanStep(
                    index=idx,
                    action=c,
                    rationale=f"Derived from prompt segment {idx+1}.",
                )
            )

        # Add guard-rail steps depending on task type
        if task_type in ("coding",):
            steps.insert(
                0,
                PlanStep(
                    index=0,
                    action="Scaffold repo and write minimal tests.",
                    rationale="Enable quick feedback and regression checks.",
                ),
            )
            # Reindex
            for i, s in enumerate(steps):
                s.index = i

        return steps

    def plan(self, prompt: str, task_type: TaskType) -> DispatchResponse:
        logger.info("Planning request: task_type=%s prompt_len=%d", task_type, len(prompt))
        steps = self._heuristic_decompose(prompt, task_type)
        # Rough token estimate: 1 token ~ 4 chars (very approximate)
        est_tokens = max(32, int(len(prompt) / 4) + 8 * len(steps))
        notes = "This plan was generated by a stub heuristic planner."
        return DispatchResponse.make(task_type=task_type, steps=steps, estimated_tokens=est_tokens, notes=notes)

class GptPlanner(StubPlanner):
    """Planner backed by OpenAI GPT-4o. Falls back to heuristics on error."""

    def plan(self, prompt: str, task_type: TaskType) -> DispatchResponse:
        api_key = os.getenv("OPENAI_API_KEY", "")
        enabled = bool(api_key) and os.getenv("PYTEST_CURRENT_TEST") is None and OpenAI is not None
        client = OpenAI(api_key=api_key) if enabled else None
        if not enabled or not client:
            return super().plan(prompt, task_type)

        try:
            sys = (
                "You are a senior software architect planning the next steps of a project. "
                "Return strictly JSON with keys: steps (list of {index, action, rationale}), estimated_tokens (int)."
            )
            user = (
                "Create a concise execution plan for the following prompt. "
                "Keep 3-6 steps. Index must start at 0 and increment by 1.\n\n"
                f"Task type: {task_type}\n"
                f"Prompt: {prompt}"
            )
            resp = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": sys},
                    {"role": "user", "content": user},
                ],
                temperature=0.2,
            )
            content = (resp.choices[0].message.content or "{}").strip()
            # Extract JSON from potential markdown fencing
            if content.startswith("```"):
                content = content.strip("`\n ")
                if content.lower().startswith("json"):
                    content = content[4:].strip()
            data = json.loads(content)
            raw_steps = data.get("steps", [])
            steps: List[PlanStep] = []
            for s in raw_steps:
                steps.append(
                    PlanStep(index=int(s.get("index", len(steps))), action=str(s.get("action", "")).strip(), rationale=str(s.get("rationale", "")).strip())
                )
            if not steps:
                # Fallback to heuristic if parse failed
                return super().plan(prompt, task_type)
            est_tokens = int(data.get("estimated_tokens", max(32, int(len(prompt) / 4) + 8 * len(steps))))

            # Memory logging for traceability
            snippet = (
                "[MODEL v11]\n"
                "component: planner\n"
                "model: gpt-4o\n"
                f"task_type: {task_type}\n"
                f"steps: {len(steps)}\n"
                f"prompt_preview: {prompt[:120]}"
            )
            add_to_memory("planner:gpt4o", snippet)

            resp = DispatchResponse.make(task_type=task_type, steps=steps, estimated_tokens=est_tokens, notes="OpenAI GPT-4o plan")
            # annotate model name
            resp.model_name = "gpt-4o"
            return resp
        except Exception as e:
            logger.exception("GPT planner error; falling back to stub: %s", e)
            return super().plan(prompt, task_type)


# Choose planner: OpenAI if configured and not under pytest, else stub
planner = GptPlanner()
